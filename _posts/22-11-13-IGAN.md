---
layout: post
title:  "Improved Techniques for Training GANs"
date: "2022-11-13"  
author: "심윤보, 차준엽"
categories: "GAN"
use_math: "true"
---

# Improved Techniques for Training GANs

## 1. Introduction
Generative adversarial networks(GANs)은 game 이론에 근거한 생성 모델이다. 

(게임이론의 핵심이라 할 수 있는 내쉬 균형은 각자가 상대방 대응에 따라, 
최선의 선택을 하고 자신의 선택을 바꾸지 않는 균형 상태를 말한다.

![image](https://user-images.githubusercontent.com/117826908/201459109-8891980c-b620-4f0d-b34d-aee5dd612fe4.png)

하지만, GANs 은 game 이론의 내쉬 균형을 찾기 보다는 비용함수의 low value를 착기 위해 gradient descent 방식을 사용한다.

즉, 이는 non-convex 비용함수와 고차원의 파라미터 공간에서 수렴을 보장하지 못한다.

본 논문에서는 GAN이 수렴이기 위한 5가지의 기술을 소개한다.


## 2. Toward Convergent GAN Training

5가지 기술은 다음과 같다.
 - Feature Matching
 - Minibatch discrimination
 - Historical averaging
 - One-sided label smoothing
 - Virtual batch normalization

### 2.1 Feature Matching

- 기존 GAN의 generator의 목적함수를 아래의 것으로 사용한다. 

![image](https://user-images.githubusercontent.com/117826908/201459436-de9de73c-b96b-48db-81d2-45151214a01a.png)

이는 Generator에 새로운 목적함수 지정하여 오버트레이닝을 방지하고, GAN의 불안정성(insatbility)을 해결한다.

Generator에서 생성한 분포가 실제 데이터의 분포를 matching 시키기 위해 Discriminator 중간층의 activation 함수를 이용한다. 

단순하게 진짜/가짜를 나누는 방식이 아닌, 진짜와 같은 feature를 가지고 있느냐? 라는 방식으로 훈련을 진행하는 것이다. 

이를 위해 새로운 손실함수를 위화 같은 방식으로 정의하고 사용한다.

여기서 f(x)는 Discriminator의 중간 층 activation 함수다. 

식을 이해해보면 Discriminator 중간층의 output이 생성에 필요한 하나의 특징(feature)이며, 

이것이 random sampling된 z에 대해 분포가 비슷한지(matching) 살펴보는 것이다.

G가 목표하는 통계치에 도달하는지는 확신할 수 없지만, 경험적으로 불안정한 GAN에 대해 효과적이라고 이야기 하고 있다.

### 2.2 Minibatch discriminator

![image](https://user-images.githubusercontent.com/117826908/201459874-3aad27fe-1b19-407c-b724-7faa4e6dd3b4.png)


## 3. Assessment of image quality
기존의 생성모델으 성능을 평가하는데 있어 주로 pit/dim이나 NLL이 사용되었다. 하지만 앞선 지표들의 값이 우수하다고 하더라도 실제 생성되는 이미지의 질은 좋지 않은 경우도 매우 많았다. 이러한 한계를 극복하기 위해 본 논문에서는 생성된 이미지가 실제 같은지에 대해 인간의 판단이 필요했고 Amazon Mechanical Turk와 같은 Crowd Sourcing을 통해 생성 이미지를 평가했다. 하지만 사람마다 기준이 달라 객관적인 기준이 없다는 점과 판단 결과에 대해 피드백을 주었을 떄 그 피드백에 의해 평가가 급격하게 변경되는 경우가 많이 있었다. 따라서 본 논문에서는 모든 생성모델에 객관적으로 사용될 수 있는 방법인 Inception Score를 제안한다.

### 3.1 Inception Model
Inception Model은 https://arxiv.org/pdf/1512.00567.pdf 에서 제안된 모델로 ImageNet 챌린지에서 우수한 성적을 거둔 모델이다. Inception model은 ImageNet 데이터에 pre-trained되었고 이미지 샘플 $(x)$ , label $(y)$ 가 있을 때 $p(y \vert x)$ 를 계산하기 위해 사용된다. 

### 3.2 Inception Score
Inception Score는 모델의 2가지 성능을 평가할 수 있는데 첫번째는 생성된 이미지의 품질이고 두번째는 샘플 생성의 다양성이다.

$$
Inception Score(IS) = exp⁡(𝔼_𝑥 (𝐾𝐿(𝑝(𝑦│𝑥)  | |  𝑝(𝑦))))
$$

$p(y \vert x)$를 


**Inception Model**
![Inception Model](https://user-images.githubusercontent.com/117570065/201459620-c9a3e242-2410-4a8e-bcd4-995cc0f4ecbd.png)


## 4. Semi-supervised learning

## 6. Experiments

## 7. Conclusion


1. Introduction
2. Related Work
3. Toward Convergent GAN Training
4. Assessment of image quality
5. Semi-supervised learning
6 Experiments 
7 Conclusion 

testt
