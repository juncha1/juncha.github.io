---
layout: post
title:  "Stochastic Backpropagation and Approximate Inference in DGM"
date: "2022-11"  
author: ""
categories: "Variational Inference"
use_math: "true"
---


# Stochastic Backpropagation and Approximate Inference in DGM

## 1. Preliminary
### 1-1 Bayesian Inference
- 사전 확률 P(z) 과 추가적인 정보를 통해 해당 대상의 사후 확률 P(z|X)을 추론하는 방법
- 주어진 데이터를 변수화시켜 사후 확률을 계산하는 것이 핵심

$$
P(z \vert X) = \frac{P(X \vert z)P(z)}{P(X)}
$$


### 1-2 변분추론(Variational Inference)
하지만 많은 경우 사후 확률 P(z|X)을 계산하는 것은 불가능하다. 따라서 아래 그림처럼 사후 확률을 알기 쉬운 분포 q(z)로 근사시켜 계산하는 것을 변분추론(Variational Inference, VI)이라 한다.

**p(z|X)를 정규분포(q(z))로 근사한 경우**
<p align="center">
  <img src="https://user-images.githubusercontent.com/117570065/200180223-0a3e7416-5c68-4b27-9576-56bd9694834c.png" alt="factorio thumbnail"/>
</p> 

변분추론을 사용하는 이유는 크게 2가지가 있다.
1. Marginal Probability를 계산하기 힘들어서
2. likelihood(P(X|z)), prior(p(z))를 복잡하게 모델링하고 싶어서

q(z)를 사후 확률에 근사시키기 위해 두 확률분포의 차이를 계산하는 데에 사용하는 Kullback Leibler Divergence(KLD) 개념 활용 → KLD가 감소하는 방향으로 q(z)를 update


## 2. Introduction
### 2-1 Latent Variable Model
기존의 generative model 연구에 대해 accurate하면서 scalalble한 model을 만들기 위한 많은 노력들이 있었다. 한 가지 예로 belief network와 같은 directed model과 latent variable 모델들은 효율성 측면에서 많은 아쉬움을 보였다. 그 이후에도 수 많은 연구들을 통해 아래 3가지 조건을 만족시키는 generative model을 만들기 위한 노력들이 있었다.
1. 데이터의 복잡한 구조 파악을 위한 **Deep Model**
2. Fast Sampling
3. Tractable and Scalable to high-dimensional data

위 조건을 만족시키기 위해 논문에서 제안한 방법은 다음과 같다.
- 가우시안 잠재변수를 더하면서 깊고 복잡한 구조를 가진 모델 구축
- Generative model과 Recognition model을 동시에 최적화
- Recognition model을 활용한 잠재 변수의 사후 확률 근사

이제부터 어떻게 위 방법들이 적용되었는지 소개하겠다.

## 3. Deep Latent Gaussian Model (DLGM)

<p align="center">
  <img src="https://user-images.githubusercontent.com/117570065/200360296-d0aa3a63-1572-447f-ae7d-a5a5297b3709.png" alt="factorio thumbnail"/>
</p> 

**How to generate data??**

DLGM은 각 layer마다 가우시안 잠재변수를 가진 deep directed graphical model이다. 데이터가 생성되는 과정은 다음과 같다. L개의 layer가 있다고 가정할 때 top-most layer인 L번째 layer의 가우시안 분포에서 샘플링(식 1) 후 matrix $G_l$을 곱하여 $h_L$을 얻는다(식 2). 그 후 $l$+1번째 $h_{l+1}$에 multi-layer perceptrons(MLPs) $T_l$을 곱하고 $l$번째 layer의 가우시안 샘플링 값 $\xi_l$과 $G_{l-1}$을 곱하여 더해준다(식 3). 그리고 최종적으로 최하단의 layer에서 근사를 통해 학습한 함수 $\pi(v \vert ·)$로부터 데이터를 생성한다(식 4).

$$
\xi_l \sim \mathcal{N}(\xi_l \vert 0, I),\quad l = 1, ..., L\qquad(1)
$$

$$
h_L = G_L\xi_L \qquad(2)
$$

$$
h_l = T_l(h_{l+1}) + G_l\xi_l, \quad l = 1... L-1\qquad(3)
$$

$$
v \sim \pi(v \vert T_0(h_1)),\qquad(4)
$$

또한 모델의 joint pdf는 다음과 같이 두 가지 방정식으로 표현될 수 있다.

$$
p(v, h) = p(v \vert h_1,\theta^g)p(h_L \vert \theta^g)p(\theta^g)\prod_{l=1}^{L-1} p_l(h_l \vert h_{l+1}, \theta^g)\qquad(5)
$$

$$
p(v, \xi) = p(v \vert h_1(\xi_{1, ... ,L}), \theta^g)p(\theta^g)\prod_{l=1}^L\mathcal{N}(\xi \vert 0, I)\qquad(6)
$$

식(5)를 식(6)으로 바꾸면서 deterministic한 부분과 stochastic한 부분을 나눌 수 있고 이로 인해 여러번의 non-linear transformation $(T_l)$ 을 통해 empirical distribution에 근사하게 됩니다.

## 4. Stochastic Backpropagation
gradient descent 방법을 적용하기 위해서는 $\nabla_{\theta}E_{q_{\theta}}[f(\xi)]$ 계산이 필요하지만 아래 2가지 이유로 직접적인 계산이 어렵다.
1. 기댓값을 계산하기 어려움
2. $q_{\theta}$에 무작위성이 포함되어 있어 역전파 불가

이 문제를 **stochastic backpropagation**을 통해 해결.

### 4.1 Gaussian Backpropagation (GBP)


















### ㅇㅇㄹ

아래 수식에서 모든 z에 대해 직접 계산을 하는 것이 불가능하기 때문에 실제로 사후 확률을 구하는 것은 불가능

$$
\begin{matrix}
argmax_\theta\log{P(X \vert \theta)} &=& \log{\sum_z{P(X, Z \vert \theta})} \\
                        &=& \log{\sum_z{P(X \vert Z, \theta})P(Z \vert \theta)} \\
\end{matrix}
$$

이에 대한 해결방법으로 z에 대한 sampling을 
