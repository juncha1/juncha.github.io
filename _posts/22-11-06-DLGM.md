---
layout: post
title:  "Stochastic Backpropagation and Approximate Inference in DGM"
date: "2022-11"  
author: ""
categories: "Variational Inference"
use_math: "true"
---


# Stochastic Backpropagation and Approximate Inference in DGM

## Preliminary
### 1-1 Bayesian Inference
- 사전 확률 P(z) 과 추가적인 정보를 통해 해당 대상의 사후 확률 P(z|X)을 추론하는 방법
- 주어진 데이터를 변수화시켜 사후 확률을 계산하는 것이 핵심

$$
P(z \vert X) = \frac{P(X \vert z)P(z)}{P(X)}
$$


### 1-2 변분추론(Variational Inference)
하지만 많은 경우 사후 확률 P(z|X)을 계산하는 것은 불가능하다. 따라서 사후 확률을 알기 쉬운 분포 q(z)로 근사시켜 계산하는 것을 변분추론(Variational Inference, VI)이라 한다. 변분추론을 사용하는 이유는 크게 2가지가 있다.

[This is an image](https://myoctocat.com/assets/images/base-octocat.svg)



1. Marginal Probability를 계산하기 힘들어서
2. likelihood(P(X|z)), prior(p(z))를 복잡하게 모델링하고 싶어서
















### ㅇㅇㄹ

아래 수식에서 모든 z에 대해 직접 계산을 하는 것이 불가능하기 때문에 실제로 사후 확률을 구하는 것은 불가능

$$
\begin{matrix}
argmax_\theta\log{P(X \vert \theta)} &=& \log{\sum_z{P(X, Z \vert \theta})} \\
                        &=& \log{\sum_z{P(X \vert Z, \theta})P(Z \vert \theta)} \\
\end{matrix}
$$

이에 대한 해결방법으로 z에 대한 sampling을 
