---
layout: post
title:  "Stochastic Backpropagation and Approximate Inference in DGM"
date: "2022-11"  
author: ""
categories: "Variational Inference"
use_math: "true"
---


# Stochastic Backpropagation and Approximate Inference in DGM

## Preliminary
### 1-1 Bayesian Inference
- 사전 확률 P(z) 과 추가적인 정보를 통해 해당 대상의 사후 확률 P(z|X)을 추론하는 방법
- 주어진 데이터를 변수화시켜 사후 확률을 계산하는 것이 핵심

$$
P(z \vert X) = \frac{P(X \vert z)P(z)}{P(X)}
$$


### 1-2 변분추론(Variational Inference)
하지만 많은 경우 사후 확률 P(z|X)을 계산하는 것은 불가능하다. 따라서 아래 그림처럼 사후 확률을 알기 쉬운 분포 q(z)로 근사시켜 계산하는 것을 변분추론(Variational Inference, VI)이라 한다.

**p(z|X)를 정규분포(q(z))로 근사한 경우**
<p align="center">
  <img src="https://user-images.githubusercontent.com/117570065/200180223-0a3e7416-5c68-4b27-9576-56bd9694834c.png" alt="factorio thumbnail"/>
</p> 

변분추론을 사용하는 이유는 크게 2가지가 있다.
1. Marginal Probability를 계산하기 힘들어서
2. likelihood(P(X|z)), prior(p(z))를 복잡하게 모델링하고 싶어서
















### ㅇㅇㄹ

아래 수식에서 모든 z에 대해 직접 계산을 하는 것이 불가능하기 때문에 실제로 사후 확률을 구하는 것은 불가능

$$
\begin{matrix}
argmax_\theta\log{P(X \vert \theta)} &=& \log{\sum_z{P(X, Z \vert \theta})} \\
                        &=& \log{\sum_z{P(X \vert Z, \theta})P(Z \vert \theta)} \\
\end{matrix}
$$

이에 대한 해결방법으로 z에 대한 sampling을 
